{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637e2bb2-69b9-4f8d-a25f-f29fa8c74419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "# Identifying all PDFs\n",
    "pdf_folder = 'data/modules'\n",
    "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8763adc4-5539-4593-8815-7f91d9449d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from PDF using pdfplumber\n",
    "def extract_pdf_text(pdf_path):\n",
    "    all_text = ''\n",
    "    with contextlib.redirect_stderr(io.StringIO()): # Use of AI to avoid warning messages\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    all_text += page_text + '\\n'\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec76e4dd-ac90-463a-a0dc-8739252751af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract department name & code\n",
    "def extract_department_code(text):\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        match = re.search(r'([A-Za-z]+) \\(([A-Za-z]{2,4})\\) course results', line) # Use of AI to generate generic re code that identifies string\n",
    "        if match:\n",
    "            department_name = match.group(1) # Use of AI to learn about .group() function\n",
    "            department_code = match.group(2)\n",
    "            break\n",
    "    return department_code, department_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c181e6e5-36f9-4681-b714-8db93002730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract Marksummary tables from text\n",
    "def extract_marksummary(text, department_code, department_name):\n",
    "    lines = text.split('\\n')\n",
    "    mark_data = []\n",
    "    excluded_data = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "\n",
    "        # Identifying table headers\n",
    "        if line.startswith('Year marks mean sd'):\n",
    "            header = line.split()\n",
    "            pos = {col: idx for idx, col in enumerate(header)}\n",
    "\n",
    "            # Identifying course code (at bottom of table)\n",
    "            course = department_code # Setting department code as default\n",
    "            for k in range(1, 7):\n",
    "                if i + k < len(lines):\n",
    "                    match = re.search(r'([A-Z0-9]+):Marksummary', lines[i + k])\n",
    "                    if match:\n",
    "                        course = match.group(1)\n",
    "                        break\n",
    "\n",
    "            # Moving to first data row (skipping header)\n",
    "            i += 1\n",
    "            course_data = []\n",
    "            skipped_rows = []\n",
    "            \n",
    "            while i < len(lines):\n",
    "                line = lines[i].strip()\n",
    "                # Break when encountering table title (at bottom of each table)\n",
    "                if re.match(r'([A-Z0-9]+):Marksummary', line) or line.startswith('MarksbyYear'):\n",
    "                    break\n",
    "\n",
    "                # Parsing data\n",
    "                if line:\n",
    "                    values = line.split()\n",
    "                    if len(values) == len(pos): # cleaning data from incomplete and misaligned rows due to missing values\n",
    "                        course_data.append({\n",
    "                            'department': department_name,\n",
    "                            'code': course,\n",
    "                            'year': values[pos['Year']],\n",
    "                            'marks': int(values[pos['marks']]),\n",
    "                            'mean': float(values[pos['mean']]),\n",
    "                            'sd': float(values[pos['sd']]),\n",
    "                            'min': float(values[pos['min']]),\n",
    "                            'q10': float(values[pos['q10']]),\n",
    "                            'q25': float(values[pos['q25']]),\n",
    "                            'median': float(values[pos['median']]),\n",
    "                            'IQR': float(values[pos['IQR']]),\n",
    "                            'q75': float(values[pos['q75']]),\n",
    "                            'q90': float(values[pos['q90']]),\n",
    "                            'q95': float(values[pos['q95']]),\n",
    "                            'max': float(values[pos['max']])\n",
    "                        })\n",
    "                        \n",
    "                    elif len(values) == 1: # Seperating excluded rows between empty rows and incomplete rows\n",
    "                        skipped_rows.append({'course': course, 'year': values[pos['Year']], 'reason': 'no data in year'})\n",
    "                        \n",
    "                    else:\n",
    "                        skipped_rows.append({'course': course, 'year': values[pos['Year']], 'reason': 'incomplete data'})\n",
    "                \n",
    "                            \n",
    "                i += 1  # Moving to next line\n",
    "\n",
    "            mark_data.extend(course_data)\n",
    "            excluded_data.extend(skipped_rows)\n",
    "\n",
    "        else:\n",
    "            i += 1  # Moving to next line\n",
    "\n",
    "    return mark_data, excluded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8abc121-2e8a-4308-8712-5f8fb989a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape all PDFs in the folder\n",
    "def process_pdfs(pdf_folder):\n",
    "    all_data = []\n",
    "    all_excl_data = []\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "        print(f\"Processing {pdf_file}...\")\n",
    "\n",
    "        # Extracting text from the PDF\n",
    "        text = extract_pdf_text(pdf_path)\n",
    "        \n",
    "        # Extracting department code and name\n",
    "        department_code, department_name = extract_department_code(text)\n",
    "\n",
    "        # Extracting mark summary data\n",
    "        mark_data, excluded_data = extract_marksummary(text, department_code, department_name)\n",
    "        \n",
    "        # Appending data\n",
    "        all_data.extend(mark_data)\n",
    "        all_excl_data.extend(excluded_data)\n",
    "\n",
    "    # Converting data\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df_excl = pd.DataFrame(all_excl_data)\n",
    "    \n",
    "    return df, df_excl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f68ad052-eef9-46b8-a7f6-87d6eb446991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AC-results-2023-24-All-Sittings.pdf...\n",
      "Processing SP-results-2023-24-All-Sittings.pdf...\n",
      "Processing ST-results-2023-24-All-Sittings.pdf...\n",
      "Processing GV-results-2023-24-All-Sittings.pdf...\n",
      "Processing PH-results-2023-24-All-Sittings.pdf...\n",
      "Processing SO-results-2023-24-All-Sittings.pdf...\n",
      "Processing HY-results-2023-24-All-Sittings.pdf...\n",
      "Processing FM-results-2023-24-All-Sittings.pdf...\n",
      "Processing MG-results-2023-24-All-Sittings.pdf...\n",
      "Processing LL-results-2023-24-All-Sittings.pdf...\n",
      "Processing IR-results-2023-24-All-Sittings.pdf...\n",
      "Processing LS-results-2023-24-All-Sittings.pdf...\n",
      "Processing MA-results-2023-24-All-Sittings.pdf...\n",
      "Processing LN-results-2023-24-All-Sittings.pdf...\n",
      "Processing AN-results-2023-24-All-Sittings.pdf...\n",
      "Processing EH-results-2023-24-All-Sittings.pdf...\n",
      "Processing EC-results-2023-24-All-Sittings.pdf...\n",
      "Processing MY-results-2023-24-All-Sittings.pdf...\n",
      "Processing PB-results-2023-24-All-Sittings.pdf...\n",
      "Processing DS-results-2023-24-All-Sittings.pdf...\n",
      "\n",
      "Data extraction complete\n",
      "\n",
      "516 rows deleted due to empty rows for years prior to introduction of new modules.\n",
      "49 rows deleted due to missing values resulting in misalignment.\n"
     ]
    }
   ],
   "source": [
    "# Scraping all PDFs & sorting data\n",
    "df, df_excl = process_pdfs(pdf_folder)\n",
    "df = df.sort_values(by=['code', 'year'], ascending=[True, True])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "empty_rows = len(df_excl[df_excl['reason'] == 'no data in year'])\n",
    "misaligned_rows = len(df_excl[df_excl['reason'] == 'incomplete data'])\n",
    "\n",
    "print('\\n'+'Data extraction complete'+'\\n')\n",
    "print(f'{empty_rows} rows deleted due to empty rows for years prior to introduction of new modules.')\n",
    "print(f'{misaligned_rows} rows deleted due to missing values resulting in misalignment.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce9ad7c1-27f9-4795-840f-e77596af5c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes seperated and saved as CSV files\n"
     ]
    }
   ],
   "source": [
    "# Separating modules and department data\n",
    "departments_df = df[df['code'].str.len() == 2]\n",
    "departments_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "modules_df = df[df['code'].str.len() > 2]\n",
    "modules_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Saving DataFrames to CSV files\n",
    "modules_df.to_csv(\"data/modules/marks_summary_modules.csv\", index=False)\n",
    "departments_df.to_csv(\"data/departments/marks_summary_departments.csv\", index=False)\n",
    "\n",
    "print('Dataframes seperated and saved as CSV files')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
